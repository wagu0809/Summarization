10/03/2019 04:13:04 PM: Loading checkpoint from ./model\model_step_1000.pt
10/03/2019 04:13:05 PM: Starting new HTTPS connection (1): s3.amazonaws.com:443
10/03/2019 04:13:06 PM: https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-config.json HTTP/1.1" 200 0
10/03/2019 04:13:06 PM: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ./temp\4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
10/03/2019 04:13:06 PM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

10/03/2019 04:13:06 PM: Starting new HTTPS connection (1): s3.amazonaws.com:443
10/03/2019 04:13:07 PM: https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin HTTP/1.1" 200 0
10/03/2019 04:13:07 PM: loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ./temp\aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
10/03/2019 04:13:11 PM: * number of parameters: 120512513
10/03/2019 04:26:52 PM: Validation xent: 6.92316 at step 1000
10/03/2019 04:26:52 PM: Loading checkpoint from ./model\model_step_2000.pt
10/03/2019 04:26:53 PM: Starting new HTTPS connection (1): s3.amazonaws.com:443
10/03/2019 04:26:54 PM: https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-config.json HTTP/1.1" 200 0
10/03/2019 04:26:54 PM: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ./temp\4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
10/03/2019 04:26:54 PM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

10/03/2019 04:26:54 PM: Starting new HTTPS connection (1): s3.amazonaws.com:443
10/03/2019 04:26:55 PM: https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin HTTP/1.1" 200 0
10/03/2019 04:26:55 PM: loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ./temp\aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
10/03/2019 04:26:57 PM: * number of parameters: 120512513
10/03/2019 04:40:43 PM: Validation xent: 6.66393 at step 2000
10/03/2019 04:40:43 PM: Loading checkpoint from ./model\model_step_3000.pt
10/03/2019 04:40:44 PM: Starting new HTTPS connection (1): s3.amazonaws.com:443
10/03/2019 04:40:45 PM: https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-config.json HTTP/1.1" 200 0
10/03/2019 04:40:45 PM: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ./temp\4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
10/03/2019 04:40:45 PM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

10/03/2019 04:40:45 PM: Starting new HTTPS connection (1): s3.amazonaws.com:443
10/03/2019 04:40:46 PM: https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin HTTP/1.1" 200 0
10/03/2019 04:40:46 PM: loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ./temp\aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
10/03/2019 04:40:48 PM: * number of parameters: 120512513
10/03/2019 04:54:27 PM: Validation xent: 6.68133 at step 3000
10/03/2019 04:54:27 PM: Loading checkpoint from ./model\model_step_4000.pt
10/03/2019 04:54:29 PM: Starting new HTTPS connection (1): s3.amazonaws.com:443
10/03/2019 04:54:30 PM: https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-config.json HTTP/1.1" 200 0
10/03/2019 04:54:30 PM: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ./temp\4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
10/03/2019 04:54:30 PM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

10/03/2019 04:54:30 PM: Starting new HTTPS connection (1): s3.amazonaws.com:443
10/03/2019 04:54:30 PM: https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin HTTP/1.1" 200 0
10/03/2019 04:54:30 PM: loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ./temp\aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
10/03/2019 04:54:33 PM: * number of parameters: 120512513
10/03/2019 05:08:09 PM: Validation xent: 6.91278 at step 4000
10/03/2019 05:08:09 PM: Loading checkpoint from ./model\model_step_5000.pt
10/03/2019 05:08:10 PM: Starting new HTTPS connection (1): s3.amazonaws.com:443
10/03/2019 05:08:11 PM: https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-config.json HTTP/1.1" 200 0
10/03/2019 05:08:11 PM: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ./temp\4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
10/03/2019 05:08:11 PM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

10/03/2019 05:08:11 PM: Starting new HTTPS connection (1): s3.amazonaws.com:443
10/03/2019 05:08:12 PM: https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin HTTP/1.1" 200 0
10/03/2019 05:08:12 PM: loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ./temp\aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
10/03/2019 05:08:14 PM: * number of parameters: 120512513
10/03/2019 05:21:50 PM: Validation xent: 7.55149 at step 5000
####################################################################################################################################

##############################################################text######################################################################
10/03/2019 05:21:51 PM: Starting new HTTPS connection (1): s3.amazonaws.com:443
10/03/2019 05:21:54 PM: https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-config.json HTTP/1.1" 200 0
10/03/2019 05:21:54 PM: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ./temp\4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
10/03/2019 05:21:54 PM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

10/03/2019 05:21:54 PM: Starting new HTTPS connection (1): s3.amazonaws.com:443
10/03/2019 05:21:55 PM: https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin HTTP/1.1" 200 0
10/03/2019 05:21:55 PM: loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ./temp\aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
10/03/2019 05:21:57 PM: * number of parameters: 120512513
10/03/2019 05:32:11 PM: Writing summaries.
10/03/2019 05:32:11 PM: Processing summaries. Saving system files to ./temp\tmpxkda78u_\system and model files to ./temp\tmpxkda78u_\model.
10/03/2019 05:32:11 PM: Processing files in ./temp\rouge-tmp-2019-10-03-17-32-01/candidate/.
10/03/2019 05:32:32 PM: Saved processed files to ./temp\tmpxkda78u_\model.
10/03/2019 05:32:32 PM: Written ROUGE configuration to ./temp\tmp4scm_dw9\rouge_conf.xml
10/03/2019 05:32:32 PM: Running ROUGE with command perl  D:\ProgramData\Anaconda3\envs\Env1\Tools\pyrouge-master\tools\ROUGE-1.5.5\ROUGE-1.5.5.pl -e D:\ProgramData\Anaconda3\envs\Env1\Tools\pyrouge-master\tools\ROUGE-1.5.5\data -c 95 -m -r 1000 -n 2 -a ./temp\tmp4scm_dw9\rouge_conf.xml
10/03/2019 05:35:02 PM: Rouges at step 2000 
>> ROUGE-F(1/2/3/l): 39.64/17.24/36.09
ROUGE-R(1/2/3/l): 50.44/21.93/45.88
10/03/2019 05:35:02 PM: Validation xent: 6.66234 at step 2000
####################################################################################################################################


10/03/2019 05:35:03 PM: Starting new HTTPS connection (1): s3.amazonaws.com:443
10/03/2019 05:35:04 PM: https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-config.json HTTP/1.1" 200 0
10/03/2019 05:35:04 PM: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ./temp\4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
10/03/2019 05:35:04 PM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

10/03/2019 05:35:04 PM: Starting new HTTPS connection (1): s3.amazonaws.com:443
10/03/2019 05:35:05 PM: https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin HTTP/1.1" 200 0
10/03/2019 05:35:05 PM: loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ./temp\aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
10/03/2019 05:35:08 PM: * number of parameters: 120512513
10/03/2019 05:45:28 PM: Writing summaries.
10/03/2019 05:45:28 PM: Processing summaries. Saving system files to ./temp\tmpymj1fn67\system and model files to ./temp\tmpymj1fn67\model.
10/03/2019 05:45:28 PM: Processing files in ./temp\rouge-tmp-2019-10-03-17-45-18/candidate/.

10/03/2019 05:45:51 PM: Saved processed files to ./temp\tmpymj1fn67\model.
10/03/2019 05:45:51 PM: Written ROUGE configuration to ./temp\tmpwrqxipn4\rouge_conf.xml
10/03/2019 05:45:51 PM: Running ROUGE with command perl  D:\ProgramData\Anaconda3\envs\Env1\Tools\pyrouge-master\tools\ROUGE-1.5.5\ROUGE-1.5.5.pl -e D:\ProgramData\Anaconda3\envs\Env1\Tools\pyrouge-master\tools\ROUGE-1.5.5\data -c 95 -m -r 1000 -n 2 -a ./temp\tmpwrqxipn4\rouge_conf.xml
10/03/2019 05:48:42 PM: Rouges at step 3000 
>> ROUGE-F(1/2/3/l): 39.98/17.44/36.34
ROUGE-R(1/2/3/l): 51.63/22.59/46.88
10/03/2019 05:48:42 PM: Validation xent: 6.61846 at step 3000
####################################################################################################################################


10/03/2019 05:48:44 PM: Starting new HTTPS connection (1): s3.amazonaws.com:443
10/03/2019 05:48:45 PM: https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-config.json HTTP/1.1" 200 0
10/03/2019 05:48:45 PM: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ./temp\4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
10/03/2019 05:48:45 PM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

10/03/2019 05:48:45 PM: Starting new HTTPS connection (1): s3.amazonaws.com:443
10/03/2019 05:48:46 PM: https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin HTTP/1.1" 200 0
10/03/2019 05:48:46 PM: loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ./temp\aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
10/03/2019 05:48:48 PM: * number of parameters: 120512513
10/03/2019 05:59:04 PM: Writing summaries.
10/03/2019 05:59:04 PM: Processing summaries. Saving system files to ./temp\tmpgyx4hjue\system and model files to ./temp\tmpgyx4hjue\model.
10/03/2019 05:59:04 PM: Processing files in ./temp\rouge-tmp-2019-10-03-17-58-54/candidate/.

10/03/2019 05:59:28 PM: Saved processed files to ./temp\tmpgyx4hjue\model.
10/03/2019 05:59:28 PM: Written ROUGE configuration to ./temp\tmpps61r92f\rouge_conf.xml
10/03/2019 05:59:28 PM: Running ROUGE with command perl  D:\ProgramData\Anaconda3\envs\Env1\Tools\pyrouge-master\tools\ROUGE-1.5.5\ROUGE-1.5.5.pl -e D:\ProgramData\Anaconda3\envs\Env1\Tools\pyrouge-master\tools\ROUGE-1.5.5\data -c 95 -m -r 1000 -n 2 -a ./temp\tmpps61r92f\rouge_conf.xml
10/03/2019 06:02:19 PM: Rouges at step 4000 
>> ROUGE-F(1/2/3/l): 39.31/17.03/35.78
ROUGE-R(1/2/3/l): 49.36/21.34/44.89
10/03/2019 06:02:19 PM: Validation xent: 7.08914 at step 4000
